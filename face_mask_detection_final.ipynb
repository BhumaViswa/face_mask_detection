{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>    FACE MASK DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importing all  important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "import random  # to shuffle the data in data list that has values with and without mask in a linear manner\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# lets do transfer learning from vgg16 hence we will import vgg and related libraries\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Input,Flatten,Dense\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=[\"with_mask\",\"without_mask\"] # categories of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Loading the Dataset and storing in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[] # list to store the images and labels\n",
    "\n",
    "\n",
    "for category in categories:                                                        # loop to iterate through the categories\n",
    "  path=os.path.join(r\"C:\\Users\\viswa\\OneDrive\\Desktop\\facemask_dataset\",category)  # path to the folder containing the images\n",
    "  print(path)       \n",
    "  # print(0)\n",
    "  label=categories.index(category)                                              # label to be assigned to the images\n",
    "\n",
    "  for file in os.listdir(path):                                                # loop to iterate through the images in the folder\n",
    "    img_path=os.path.join(path,file)\n",
    "    img=cv2.imread(img_path)\n",
    "    img=cv2.resize(img,(224,224))                                              # resizing the image to 224*224\n",
    "\n",
    "    \n",
    "    data.append([img,label])                                                 # appending the image and label to the data list\n",
    "\n",
    "# path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data)) # length of the data list\n",
    "data[0][0].shape # shape of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>shuffling the data and separating the input and target features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random   # to shuffle the data in data list that has values with and without mask in a linear manner\n",
    "random.shuffle(data) # shuffling the data\n",
    "\n",
    "X=[]    # list to store the images\n",
    "y=[]    # list to store the labels\n",
    "for features,label in data:         # loop to iterate through the data list\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X=np.array(X)               # converting the list to numpy array\n",
    "y=np.array(y)                   # converting the list to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape # shape of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape         # shape of the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X/255.0       # normalizing the image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>splitting the data in to train test samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)           # splitting the data into train and test with test size of 20%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape    # shape of the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape        # shape of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do transfer learning from vg16\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Input,Flatten,Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Transfer learning with VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg=VGG16()   # importing the vgg16 model\n",
    "vgg.summary()  # summary of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential    # to add layers one by one\n",
    "model=Sequential()        # creating a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers[:-1]:   # loop to iterate through the layers of vgg16 model\n",
    "    model.add(layer)            # adding the layers to the model\n",
    "\n",
    "model.summary()     # summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:              # loop to iterate through the layers of the model\n",
    "\n",
    "    layer.trainable=False               # making the layers of the model non trainable(i.e freezing the layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()             # summary of the model after freezing the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add last layer of our data to vgg model\n",
    "model.add(Dense(1,activation='sigmoid'))   # adding the last layer to the model with sigmoid activation function\n",
    "model.summary()                             # summary of the model after adding the last layer to the vgg model with sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])  # compiling the model with adam optimizer and binary crossentropy as loss function and accuracy as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Fitting the data and checking the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train,epochs=5,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>we got accuracy of 0.94 in train and 0.93 in validation test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use opencv to detect the face and mask in video\n",
    "import cv2                  # importing opencv library\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image     # importing image from keras preprocessing library\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_mask(img):                  # function to detect the face mask\n",
    "    \n",
    "    y_pred=model.predict(img.reshape(1,224,224,3))    # predicting the image\n",
    "    return y_pred[0][0]                                 # returning the prediction\n",
    "    # return img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_classess(y_pred):               # function to predict the classes\n",
    "    \n",
    "    if y_pred<0.5:\n",
    "        print(\"with mask\")\n",
    "    else:\n",
    "        print(\"without mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_label(img,text,pos,bg_color):          # function to draw the label\n",
    "\n",
    "    text_size=cv2.getTextSize(text,cv2.FONT_HERSHEY_SIMPLEX,1,cv2.FILLED)\n",
    "    end_x=pos[0]+text_size[0][0]+2\n",
    "    end_y=pos[1]+text_size[0][1]-2\n",
    "\n",
    "    cv2.rectangle(img,pos,(end_x,end_y),bg_color,cv2.FILLED)\n",
    "    cv2.putText(img,text,pos,cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0),1,cv2.LINE_AA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>motion capturing to detect face mask on moving people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)     # capturing the video from the webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "while True:                             # loop to iterate through the video\n",
    "\n",
    "    ret,frame=cap.read()                        # ret will return true if the frame is available\n",
    "\n",
    "    img=cv2.resize(frame,(224,224))             # resizing the image to 224*224\n",
    "    y_predict=detect_face_mask(img)             # predicting the image\n",
    "    # print(y_predict)\n",
    "\n",
    "    # predict_classess(y_predict)\n",
    "\n",
    "\n",
    "    if y_predict<=0.5:                             # if the prediction is less than 0.5 then the person is wearing mask\n",
    "        draw_label(frame,\"mask\",(20,20),(0,255,0))\n",
    "    else:\n",
    "        draw_label(frame,\"no mask\",(20,20),(0,0,255))\n",
    "    \n",
    "\n",
    "\n",
    "    cv2.imshow(\"window\",frame)\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(1)&0xFF==ord('x'):\n",
    "        break\n",
    "        # video can break by pressing x key\n",
    "\n",
    "\n",
    "xxx\n",
    "\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
